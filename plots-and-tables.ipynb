{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary plots and tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pathlib import Path\n",
    "\n",
    "from astropy.table import join, Table\n",
    "from astropy import units as u\n",
    "from astropy.cosmology import Planck15 as cosmo, z_at_value\n",
    "from matplotlib import pyplot as plt\n",
    "from ligo.skymap.util import sqlite\n",
    "from IPython.display import Markdown\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "from scipy import optimize\n",
    "from scipy import special\n",
    "from scipy import stats\n",
    "from scikits import bootstrap\n",
    "import seaborn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def betabinom_k_n(k, n):\n",
    "    return stats.betabinom(n, k + 1, n - k + 1)\n",
    "\n",
    "\n",
    "@np.vectorize\n",
    "def poisson_lognormal_rate_cdf(k, mu, sigma):\n",
    "    lognorm_pdf = stats.lognorm(s=sigma, scale=np.exp(mu)).pdf\n",
    "\n",
    "    def func(lam):\n",
    "        prior = lognorm_pdf(lam)\n",
    "        poisson_pdf = np.exp(special.xlogy(k, lam) - special.gammaln(k + 1) - lam)\n",
    "        poisson_cdf = special.gammaincc(k + 1, lam)\n",
    "        return poisson_cdf * prior\n",
    "\n",
    "    # Marginalize over lambda.\n",
    "    #\n",
    "    # Note that we use scipy.integrate.odeint instead\n",
    "    # of scipy.integrate.quad because it is important for the stability of\n",
    "    # root_scalar below that we calculate the pdf and the cdf at the same time,\n",
    "    # using the same exact quadrature rule.\n",
    "    cdf, _ = integrate.quad(func, 0, np.inf, epsabs=0)\n",
    "    return cdf\n",
    "\n",
    "\n",
    "@np.vectorize\n",
    "def poisson_lognormal_rate_quantiles(p, mu, sigma):\n",
    "    \"\"\"Find the quantiles of a Poisson distribution with\n",
    "    a log-normal prior on its rate.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : float\n",
    "        The quantiles at which to find the number of counts.\n",
    "    mu : float\n",
    "        The mean of the log of the rate.\n",
    "    sigma : float\n",
    "        The standard deviation of the log of the rate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    k : float\n",
    "        The number of events.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This algorithm treats the Poisson count k as a continuous\n",
    "    real variable so that it can use the scipy.optimize.root_scalar\n",
    "    root finding/polishing algorithms.\n",
    "    \"\"\"\n",
    "    def func(k):\n",
    "        return poisson_lognormal_rate_cdf(k, mu, sigma) - p\n",
    "\n",
    "    if func(0) >= 0:\n",
    "        return 0\n",
    "\n",
    "    result = optimize.root_scalar(func, bracket=[0, 1e6])\n",
    "    return result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_with_errorbars(mid, lo, hi):\n",
    "    plus = hi - mid\n",
    "    minus = mid - lo\n",
    "    smallest = min(max(0, plus), max(0, minus))\n",
    "\n",
    "    if smallest == 0:\n",
    "        return str(mid), '0', '0'\n",
    "    decimals = 1 - int(np.floor(np.log10(smallest)))\n",
    "\n",
    "    if all(np.issubdtype(type(_), np.integer) for _ in (mid, lo, hi)):\n",
    "        decimals = min(decimals, 0)\n",
    "\n",
    "    plus, minus, mid = np.round([plus, minus, mid], decimals)\n",
    "    if decimals > 0:\n",
    "        fstring = '%%.0%df' % decimals\n",
    "    else:\n",
    "        fstring = '%d'\n",
    "    return [fstring % _ for _ in [mid, minus, plus]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.9  # Confidence band for histograms\n",
    "run_names = run_dirs = ['O3', 'O4a', 'O4', 'O5']\n",
    "pops = ['BNS', 'NSBH', 'BBH']  # Populations\n",
    "classification_names = pops\n",
    "classification_colors = seaborn.color_palette(n_colors=len(classification_names))\n",
    "fieldnames = ['area(90)', 'vol(90)', 'distance']\n",
    "fieldlabels = ['90% cred. area (deg²)',\n",
    "               '90% cred. comoving volume (10⁶ Mpc³)',\n",
    "               'Luminosity distance (Mpc)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fiducial rates in Gpc$^{-3}$ yr$^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower 5% and upper 95% quantiles of log normal distribution\n",
    "rates_table = Table(\n",
    "    [\n",
    "        # # BNS rate from GWTC-2\n",
    "        # # https://doi.org/10.3847/2041-8213/abe949\n",
    "        # {'population': 'BNS', 'lower': 80.00, 'mid': 320.0, 'upper': 810.0},\n",
    "        # # NSBH rate from GW200105 and GW200115 paper\n",
    "        # # https://doi.org/10.3847/2041-8213/ac082e\n",
    "        # {'population': 'NSBH', 'lower': 61.0, 'mid': 130.0, 'upper': 242.0},\n",
    "        # # BBH rate from GWTC-2\n",
    "        # # https://doi.org/10.3847/2041-8213/abe949\n",
    "        # {'population': 'BBH', 'lower': 15.3, 'mid': 23.9, 'upper': 38.2}\n",
    "\n",
    "        # O3 R&P paper Table II row 1 last column\n",
    "        {'population': 'BNS', 'lower': 100., 'mid': 240., 'upper': 510.},\n",
    "        {'population': 'NSBH', 'lower': 100., 'mid': 240., 'upper': 510.},\n",
    "        {'population': 'BBH', 'lower': 100., 'mid': 240., 'upper': 510.}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# For splitting into BNS, NSBH, and BBH populations\n",
    "ns_max_mass = 3\n",
    "\n",
    "# Calculate effective rate density for each sub-population\n",
    "table = Table.read('farah.h5')\n",
    "source_mass1 = table['mass1']\n",
    "source_mass2 = table['mass2']\n",
    "rates_table['mass_fraction'] = np.asarray([np.sum((source_mass1 < ns_max_mass) & (source_mass2 < ns_max_mass)),\n",
    "                                           np.sum((source_mass1 >= ns_max_mass) & (source_mass2 < ns_max_mass)),\n",
    "                                           np.sum((source_mass1 >= ns_max_mass) & (source_mass2 >= ns_max_mass))]) / len(table)\n",
    "for key in ['lower', 'mid', 'upper']:\n",
    "    rates_table[key] *= rates_table['mass_fraction']\n",
    "del table, source_mass1, source_mass2\n",
    "\n",
    "standard_90pct_interval, = np.diff(stats.norm.interval(0.9))\n",
    "rates_table['mu'] = np.log(rates_table['mid'])\n",
    "rates_table['sigma'] = (np.log(rates_table['upper']) - np.log(rates_table['lower'])) / standard_90pct_interval\n",
    "\n",
    "rates_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiducial_log_rates = np.asarray(rates_table['mu'])\n",
    "fiducial_log_rate_errs = np.asarray(rates_table['sigma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables = {}\n",
    "for run_name, run_dir in zip(tqdm(run_names), run_dirs):\n",
    "    path = Path('runs') / run_dir / 'farah'\n",
    "    allsky = Table.read(str(path / 'allsky.dat'), format='ascii.fast_tab')\n",
    "    injections = Table.read(str(path / 'injections.dat'), format='ascii.fast_tab')\n",
    "    allsky.rename_column('coinc_event_id', 'event_id')\n",
    "    injections.rename_column('simulation_id', 'event_id')\n",
    "    table = join(allsky, injections)\n",
    "\n",
    "    # Convert from Mpc^3 to 10^6 Mpc^3\n",
    "    for colname in ['searched_vol', 'vol(20)', 'vol(50)', 'vol(90)']:\n",
    "        table[colname] *= 1e-6\n",
    "\n",
    "    with sqlite.open(str(path / 'events.sqlite'), 'r') as db:\n",
    "        # Get simulated rate from LIGO-LW process table\n",
    "        (result,), = db.execute(\n",
    "            'SELECT comment FROM process WHERE program = ?',\n",
    "            ('bayestar-inject',))\n",
    "        table.meta['rate'] = u.Quantity(result)\n",
    "\n",
    "        # Get simulated detector network from LIGO-LW process table\n",
    "        (result,), = db.execute(\n",
    "            'SELECT ifos FROM process WHERE program = ?',\n",
    "            ('bayestar-realize-coincs',))\n",
    "        table.meta['network'] = result.replace('1', '').replace(',', '')\n",
    "\n",
    "        # Get number of Monte Carlo samples from LIGO-LW process_params table\n",
    "        (result,), = db.execute(\n",
    "            'SELECT value FROM process_params WHERE program = ? AND param = ?',\n",
    "            ('bayestar-inject', '--nsamples'))\n",
    "        table.meta['nsamples'] = int(result)\n",
    "\n",
    "    # Split by source frame mass\n",
    "    z = z_at_value(cosmo.luminosity_distance, table['distance'] * u.Mpc).to_value(u.dimensionless_unscaled)\n",
    "    zp1 = z + 1\n",
    "    source_mass1 = table['mass1'] / zp1\n",
    "    source_mass2 = table['mass2'] / zp1\n",
    "    tables[run_name] = {}\n",
    "    # Note: copy() below so that we deep-copy table.meta\n",
    "    tables[run_name]['BNS'] = table[(source_mass1 < ns_max_mass) & (source_mass2 < ns_max_mass)].copy()\n",
    "    tables[run_name]['NSBH'] = table[(source_mass1 >= ns_max_mass) & (source_mass2 < ns_max_mass)].copy()\n",
    "    tables[run_name]['BBH'] = table[(source_mass1 >= ns_max_mass) & (source_mass2 >= ns_max_mass)].copy()\n",
    "\n",
    "    for key in ['BNS', 'NSBH', 'BBH']:\n",
    "        rates_row, = rates_table[rates_table['population'] == key]\n",
    "        tables[run_name][key].meta['rate'] *= rates_row['mass_fraction']\n",
    "\n",
    "    del allsky, injections, table, z, zp1, source_mass1, source_mass2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load old Living Review data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "old_tables = {}\n",
    "\n",
    "for pop in tqdm(['BNS', 'NSBH', 'BBH']):\n",
    "    url_root = f'https://git.ligo.org/emfollow/obs-scenarios-2019-fits-files/-/raw/master/O3_HLV/{pop.lower()}_astro/'\n",
    "    allsky = Table.read(f'{url_root}/allsky.dat', format='ascii')\n",
    "    injections = Table.read(f'{url_root}/injections.dat', format='ascii')\n",
    "    coincs = Table.read(f'{url_root}/coincs.dat', format='ascii')\n",
    "    table = join(allsky, coincs, 'coinc_event_id')\n",
    "    table = join(table, injections, 'simulation_id')\n",
    "    table['vol(90)'] *= 1e-6\n",
    "    old_tables[pop] = table\n",
    "    del allsky, injections, coincs, table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = [plt.subplots()[1] for _ in range(len(fieldnames))]\n",
    "colors = seaborn.color_palette('colorblind', len(tables))\n",
    "linestyles = ['-', '--', ':']\n",
    "\n",
    "for ax, fieldlabel in zip(axs, fieldlabels):\n",
    "    ax.set_xlabel(fieldlabel)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_yticks([0, 0.25, 0.50, 0.75, 1])\n",
    "    ax.set_ylabel('Cumulative fraction of events')\n",
    "    ax.legend(\n",
    "        [plt.Line2D([], [], linestyle=linestyle, color='black') for linestyle in linestyles] +\n",
    "        [plt.Rectangle((0, 0), 0, 0, facecolor=color) for color in colors],\n",
    "        pops + run_names)\n",
    "\n",
    "axs[0].set_xlim(1e-1, 86400)\n",
    "axs[1].set_xlim(1e-5, 1e4)\n",
    "axs[2].set_xlim(1e1, 1e4)\n",
    "\n",
    "ax = axs[2]\n",
    "zax = ax.twiny()\n",
    "zax.set_xlim(*ax.get_xlim())\n",
    "zax.set_xscale(ax.get_xscale())\n",
    "\n",
    "zax.minorticks_off()\n",
    "n = np.arange(2, 10)\n",
    "z = np.concatenate([0.001 * n, 0.01 * n, 0.1 * n, n])\n",
    "minor = cosmo.luminosity_distance(z).to_value(u.Mpc)\n",
    "minor = minor[minor > ax.get_xlim()[0]]\n",
    "minor = minor[minor < ax.get_xlim()[1]]\n",
    "zax.set_xticks(minor, minor=True)\n",
    "zax.set_xticklabels([], minor=True)\n",
    "\n",
    "z = [0.01, 0.1, 1]\n",
    "zax.set_xticks(cosmo.luminosity_distance(z).to_value(u.Mpc))\n",
    "zax.set_xticklabels([str(_) for _ in z])\n",
    "zax.set_xlabel('Redshift')\n",
    "\n",
    "for irun, (run_name, tables1) in enumerate(tables.items()):\n",
    "    for ipop, (pop, table) in enumerate(tables1.items()):\n",
    "        for ifield, fieldname in enumerate(fieldnames):\n",
    "            data = table[fieldname]\n",
    "            data = data[np.isfinite(data)]\n",
    "            ax = axs[ifield]\n",
    "            t = np.geomspace(*ax.get_xlim(), 100)\n",
    "            kde = stats.gaussian_kde(np.asarray(np.log(data)))\n",
    "            (std,), = np.sqrt(kde.covariance)\n",
    "            y = stats.norm(kde.dataset.ravel(), std).cdf(np.log(t)[:, np.newaxis]).mean(1)\n",
    "            ax.plot(t, y, color=colors[irun], linestyle=linestyles[ipop])\n",
    "\n",
    "for ax, fieldname in zip(axs, fieldnames):\n",
    "    ax.figure.savefig(f'runs/{fieldname}.pdf')\n",
    "    ax.figure.savefig(f'runs/{fieldname}.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons with O3 public alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3_data = Table.read('public-alerts.dat', format='ascii')\n",
    "o3_data['vol(90)'] *= 1e-6\n",
    "\n",
    "o3_data_by_classification = o3_data.group_by(o3_data['classification']).groups\n",
    "o3_data_by_classification = dict(zip(o3_data_by_classification.keys, o3_data_by_classification))\n",
    "\n",
    "o3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'O3'\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(pops), len(fieldnames),\n",
    "    sharex='col', sharey=True,\n",
    "    gridspec_kw=dict(bottom=0.08, left=0.08, top=0.92, right=0.95),\n",
    "    figsize=(7.3, 6))\n",
    "\n",
    "for ax, fieldlabel in zip(axs[-1], fieldlabels):\n",
    "    ax.set_xlabel(fieldlabel)\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "ax = axs[1][0]\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_yticks([0, 0.25, 0.50, 0.75, 1])\n",
    "ax.set_ylabel('Cumulative fraction of events')\n",
    "\n",
    "axs[0, 0].set_xlim(1e0, 86400)\n",
    "axs[0, 1].set_xlim(1e-3, 1e4)\n",
    "axs[0, 2].set_xlim(1e1, 1e4)\n",
    "\n",
    "for pop, color, ax in zip(pops, classification_colors, axs[:, 0]):\n",
    "    ax.text(\n",
    "        0.05, 0.95, pop,\n",
    "        transform=ax.transAxes,\n",
    "        color=color, va='top')\n",
    "\n",
    "for ax in axs[::-1, fieldnames.index('distance')]:\n",
    "    ax2 = ax.twiny()\n",
    "    ax2.set_xlim(*ax.get_xlim())\n",
    "    ax2.set_xscale(ax.get_xscale())\n",
    "\n",
    "    ax2.minorticks_off()\n",
    "    n = np.arange(2, 10)\n",
    "    z = np.concatenate([0.001 * n, 0.01 * n, 0.1 * n, n])\n",
    "    minor = cosmo.luminosity_distance(z).to_value(u.Mpc)\n",
    "    minor = minor[minor > ax.get_xlim()[0]]\n",
    "    minor = minor[minor < ax.get_xlim()[1]]\n",
    "    ax2.set_xticks(minor, minor=True)\n",
    "    ax2.set_xticklabels([], minor=True)\n",
    "\n",
    "    z = [0.01, 0.1, 1]\n",
    "    ax2.set_xticks(cosmo.luminosity_distance(z).to_value(u.Mpc))\n",
    "ax2.set_xticklabels([f'$z$={_}' for _ in z])\n",
    "\n",
    "for ax in axs[::-1, fieldnames.index('area(90)')]:\n",
    "    ax2 = ax.twiny()\n",
    "    ax2.set_xlim(*ax.get_xlim())\n",
    "    ax2.set_xscale(ax.get_xscale())\n",
    "\n",
    "    ax2.minorticks_off()\n",
    "    ticks = [3, 9.6, 47]\n",
    "    ticklabels = ['DECam', 'VRO', 'ZTF']\n",
    "    ax2.set_xticks(ticks)\n",
    "ax2.set_xticklabels(ticklabels)\n",
    "label1, *_ = ax2.xaxis.get_ticklabels()\n",
    "label1.set_ha('right')\n",
    "\n",
    "for pop, color, axrow in zip(pops, classification_colors, axs):\n",
    "    for fieldname, ax in zip(fieldnames, axrow):\n",
    "\n",
    "        medians = []\n",
    "        for data, label, linewidth in [\n",
    "                    [old_tables[pop][fieldname], 'LRR', 0.5 * plt.rcParams['lines.linewidth']],\n",
    "                    [tables[run_name][pop][fieldname], 'this work', plt.rcParams['lines.linewidth']]\n",
    "                ]:\n",
    "            data = data[np.isfinite(data)]\n",
    "            medians.append(np.median(data))\n",
    "            kde = stats.gaussian_kde(np.asarray(np.log(data)))\n",
    "            (std,), = np.sqrt(kde.covariance)\n",
    "            t = np.geomspace(*ax.get_xlim(), 100)\n",
    "            y = stats.norm(kde.dataset.ravel(), std).cdf(np.log(t)[:, np.newaxis]).mean(1)\n",
    "            ax.plot(t, y, color=color, linewidth=linewidth, label=label)\n",
    "\n",
    "        if fieldname != 'distance':\n",
    "            ax.annotate(\n",
    "                '', (medians[1], 0.5), (medians[0], 0.5),\n",
    "                arrowprops=dict(\n",
    "                    arrowstyle='-|>', color=color,\n",
    "                    shrinkA=4, shrinkB=4,\n",
    "                    linewidth=plt.rcParams['lines.linewidth']))\n",
    "\n",
    "        data = o3_data_by_classification[pop][fieldname]\n",
    "        t = np.minimum(np.concatenate(((-np.inf,), np.sort(data))), 10 * ax.get_xlim()[-1])\n",
    "        y = np.arange(len(data) + 1) / len(data)\n",
    "        ax.plot(t, y, color='black', drawstyle='steps-post', label='O3 alerts')\n",
    "\n",
    "axs[-1, -1].legend(frameon=False)\n",
    "fig.align_labels()\n",
    "fig.savefig('runs/o3-comparison.pdf')\n",
    "fig.savefig('runs/o3-comparison.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projections for next several observing runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyles = ['-', '--', ':', '-.']\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(pops), len(fieldnames),\n",
    "    sharex='col', sharey=True,\n",
    "    gridspec_kw=dict(bottom=0.08, left=0.08, top=0.92, right=0.95),\n",
    "    figsize=(7.3, 6))\n",
    "\n",
    "for ax, fieldlabel in zip(axs[-1], fieldlabels):\n",
    "    ax.set_xlabel(fieldlabel)\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "ax = axs[1][0]\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_yticks([0, 0.25, 0.50, 0.75, 1])\n",
    "ax.set_ylabel('Cumulative fraction of events')\n",
    "\n",
    "axs[0, 0].set_xlim(1e0, 86400)\n",
    "axs[0, 1].set_xlim(1e-3, 1e4)\n",
    "axs[0, 2].set_xlim(1e1, 1e4)\n",
    "\n",
    "for pop, color, ax in zip(pops, classification_colors, axs[:, 0]):\n",
    "    ax.text(\n",
    "        0.05, 0.95, pop,\n",
    "        transform=ax.transAxes,\n",
    "        color=color, va='top')\n",
    "\n",
    "for ax in axs[::-1, fieldnames.index('distance')]:\n",
    "    ax2 = ax.twiny()\n",
    "    ax2.set_xlim(*ax.get_xlim())\n",
    "    ax2.set_xscale(ax.get_xscale())\n",
    "\n",
    "    ax2.minorticks_off()\n",
    "    n = np.arange(2, 10)\n",
    "    z = np.concatenate([0.001 * n, 0.01 * n, 0.1 * n, n])\n",
    "    minor = cosmo.luminosity_distance(z).to_value(u.Mpc)\n",
    "    minor = minor[minor > ax.get_xlim()[0]]\n",
    "    minor = minor[minor < ax.get_xlim()[1]]\n",
    "    ax2.set_xticks(minor, minor=True)\n",
    "    ax2.set_xticklabels([], minor=True)\n",
    "\n",
    "    z = [0.01, 0.1, 1]\n",
    "    ax2.set_xticks(cosmo.luminosity_distance(z).to_value(u.Mpc))\n",
    "ax2.set_xticklabels([f'$z$={_}' for _ in z])\n",
    "\n",
    "for ax in axs[::-1, fieldnames.index('area(90)')]:\n",
    "    ax2 = ax.twiny()\n",
    "    ax2.set_xlim(*ax.get_xlim())\n",
    "    ax2.set_xscale(ax.get_xscale())\n",
    "\n",
    "    ax2.minorticks_off()\n",
    "    ticks = [3, 9.6, 47]\n",
    "    ticklabels = ['DECam', 'VRO', 'ZTF']\n",
    "    ax2.set_xticks(ticks)\n",
    "ax2.set_xticklabels(ticklabels)\n",
    "label1, *_ = ax2.xaxis.get_ticklabels()\n",
    "label1.set_ha('right')\n",
    "\n",
    "for pop, color, axrow in zip(pops, classification_colors, axs):\n",
    "    for fieldname, ax in zip(fieldnames, axrow):\n",
    "        for run_name, linestyle in zip(run_names, linestyles):\n",
    "            data = tables[run_name][pop][fieldname]\n",
    "\n",
    "            data = data[np.isfinite(data)]\n",
    "            medians.append(np.median(data))\n",
    "            kde = stats.gaussian_kde(np.asarray(np.log(data)))\n",
    "            (std,), = np.sqrt(kde.covariance)\n",
    "            t = np.geomspace(*ax.get_xlim(), 100)\n",
    "            y = stats.norm(kde.dataset.ravel(), std).cdf(np.log(t)[:, np.newaxis]).mean(1)\n",
    "            ax.plot(t, y, color=color, linestyle=linestyle, linewidth=linewidth, label=run_name)\n",
    "\n",
    "axs[-1, -1].legend()\n",
    "fig.align_labels()\n",
    "fig.savefig('runs/predictions.pdf')\n",
    "fig.savefig('runs/predictions.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyles = ['-', '--', ':']\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(pops), len(fieldnames),\n",
    "    sharex='col', sharey=True,\n",
    "    gridspec_kw=dict(bottom=0.08, left=0.08, top=0.92, right=0.95),\n",
    "    figsize=(7.3, 6))\n",
    "\n",
    "for ax, fieldlabel in zip(axs[-1], fieldlabels):\n",
    "    ax.set_xlabel(fieldlabel)\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "ax = axs[1][0]\n",
    "ax.set_ylim(1, 1000)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Cumulative detection rate (events / year)')\n",
    "\n",
    "axs[0, 0].set_xlim(1e0, 86400)\n",
    "axs[0, 1].set_xlim(1e-3, 1e4)\n",
    "axs[0, 2].set_xlim(1e1, 1e4)\n",
    "\n",
    "for pop, color, ax in zip(pops, classification_colors, axs[:, 0]):\n",
    "    ax.text(\n",
    "        0.05, 0.95, pop,\n",
    "        transform=ax.transAxes,\n",
    "        color=color, va='top')\n",
    "\n",
    "for ax in axs[::-1, fieldnames.index('distance')]:\n",
    "    ax2 = ax.twiny()\n",
    "    ax2.set_xlim(*ax.get_xlim())\n",
    "    ax2.set_xscale(ax.get_xscale())\n",
    "\n",
    "    ax2.minorticks_off()\n",
    "    n = np.arange(2, 10)\n",
    "    z = np.concatenate([0.001 * n, 0.01 * n, 0.1 * n, n])\n",
    "    minor = cosmo.luminosity_distance(z).to_value(u.Mpc)\n",
    "    minor = minor[minor > ax.get_xlim()[0]]\n",
    "    minor = minor[minor < ax.get_xlim()[1]]\n",
    "    ax2.set_xticks(minor, minor=True)\n",
    "    ax2.set_xticklabels([], minor=True)\n",
    "\n",
    "    z = [0.01, 0.1, 1]\n",
    "    ax2.set_xticks(cosmo.luminosity_distance(z).to_value(u.Mpc))\n",
    "ax2.set_xticklabels([f'$z$={_}' for _ in z])\n",
    "\n",
    "for ax, pop, fiducial_log_rate in zip(axs[::-1, fieldnames.index('distance')], reversed(pops), reversed(fiducial_log_rates)):\n",
    "    ax3 = ax.twinx()\n",
    "    ax3.set_ylim(*ax.get_ylim())\n",
    "    ax3.set_yscale(ax.get_yscale())\n",
    "    ax3.set_yticks([len(tables[run_name][pop]) * np.exp(fiducial_log_rate) / tables[run_name][pop].meta['rate'].to_value(u.Gpc**-3 * u.yr**-1) for run_name in run_names])\n",
    "    ax3.set_yticklabels(run_names)\n",
    "    ax3.tick_params(length=0)\n",
    "    ax3.minorticks_off()\n",
    "\n",
    "for ax in axs[::-1, fieldnames.index('area(90)')]:\n",
    "    ax2 = ax.twiny()\n",
    "    ax2.set_xlim(*ax.get_xlim())\n",
    "    ax2.set_xscale(ax.get_xscale())\n",
    "\n",
    "    ax2.minorticks_off()\n",
    "    ticks = [3, 9.6, 47]\n",
    "    ticklabels = ['DECam', 'VRO', 'ZTF']\n",
    "    ax2.set_xticks(ticks)\n",
    "ax2.set_xticklabels(ticklabels)\n",
    "label1, *_ = ax2.xaxis.get_ticklabels()\n",
    "label1.set_ha('right')\n",
    "\n",
    "for pop, color, axrow in zip(pops, classification_colors, axs):\n",
    "    for fieldname, ax in zip(fieldnames, axrow):\n",
    "        for run_name, linestyle in zip(reversed(run_names), reversed(linestyles)):\n",
    "            data = tables[run_name][pop][fieldname]\n",
    "            rate_row, = rates_table[rates_table['population'] == pop]\n",
    "\n",
    "            data = data[np.isfinite(data)]\n",
    "            medians.append(np.median(data))\n",
    "            kde = stats.gaussian_kde(np.asarray(np.log(data)))\n",
    "            (std,), = np.sqrt(kde.covariance)\n",
    "            t = np.geomspace(*ax.get_xlim(), 100)\n",
    "            y = stats.norm(kde.dataset.ravel(), std).cdf(np.log(t)[:, np.newaxis]).mean(1)\n",
    "            scale = len(data) / tables[run_name][pop].meta['rate'].to_value(u.Gpc**-3 * u.yr**-1)\n",
    "            ymid = y * scale * rate_row['mid']\n",
    "            ylo = y * scale * rate_row['lower']\n",
    "            yhi = y * scale * rate_row['upper']\n",
    "            ax.plot(t, ymid, color=color, linestyle=linestyle, linewidth=linewidth, label=run_name)\n",
    "            ax.fill_between(t, ylo, yhi, color=color, alpha=0.25)\n",
    "\n",
    "fig.align_labels()\n",
    "fig.savefig('runs/annual-predictions.pdf')\n",
    "fig.savefig('runs/annual-predictions.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabulated statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = np.random.default_rng(150914)\n",
    "statfunc = np.nanmedian\n",
    "f = io.StringIO()\n",
    "with open('runs/summary.rst', 'w') as f_rst:\n",
    "    print('+-----------+-----------+---------------+---------------+---------------+', file=f_rst)\n",
    "    print('|           |           | Source class                                  |', file=f_rst)\n",
    "    print('| Observing |           +---------------+---------------+---------------+', file=f_rst)\n",
    "    print('| run       | Network   | BNS           | NSBH          | BBH           |', file=f_rst)\n",
    "    print('+===========+===========+===============+===============+===============+', file=f_rst)\n",
    "    for fieldname, fieldlabel in zip(fieldnames + ['volume', 'rate', 'merger_rate_density'], fieldlabels + ['Sensitive volume (Gpc$^3$)', 'Annual number of detections', 'Merger rate density (Gpc$^{-3}$ yr$^{-1}$)']):\n",
    "        print('| {:69s} |'.format(fieldlabel), file=f_rst)\n",
    "        print('<table>', file=f)\n",
    "        print('<caption>', fieldlabel, '</caption>', file=f)\n",
    "        print('<thead>', file=f)\n",
    "        print('<tr>', file=f)\n",
    "        print('<th>', 'Run', '</th>', file=f)\n",
    "        for pop in pops:\n",
    "            print('<th>', pop, '</th>', file=f)\n",
    "        print('</tr>', file=f)\n",
    "        print('</thead>', file=f)\n",
    "        print('<tbody>', file=f)\n",
    "        for irun, (run, tables1) in enumerate(tables.items()):\n",
    "            print('<tr>', file=f)\n",
    "            print('<th>', run, '</th>', file=f)\n",
    "\n",
    "            results = {}\n",
    "            for ipop, (pop, table) in enumerate(tables1.items()):\n",
    "                rate = table.meta['rate'].to_value(u.Gpc**-3 * u.yr**-1)\n",
    "                nsamples = table.meta['nsamples']\n",
    "                fiducial_log_rate = fiducial_log_rates[ipop]\n",
    "                fiducial_log_rate_err = fiducial_log_rate_errs[ipop]\n",
    "                mu = fiducial_log_rate + np.log(len(table) / rate)\n",
    "                sigma = fiducial_log_rate_err\n",
    "\n",
    "                quantiles = [0.05, 0.5, 0.95]\n",
    "                if fieldname == 'volume':\n",
    "                    lo, mid, hi = betabinom_k_n(len(table), nsamples).ppf(quantiles) / rate\n",
    "                elif fieldname == 'rate':\n",
    "                    lo, mid, hi = poisson_lognormal_rate_quantiles(quantiles, mu, sigma)\n",
    "                    lo = int(np.floor(lo))\n",
    "                    mid = int(np.round(mid))\n",
    "                    hi = int(np.ceil(hi))\n",
    "                elif fieldname == 'merger_rate_density':\n",
    "                    (lo, mid, hi), = rates_table[rates_table['population'] == pop]['lower', 'mid', 'upper']\n",
    "                else:\n",
    "                    data = table[fieldname]\n",
    "                    lo, mid, hi = bootstrap.ci(data, statfunc, quantiles, seed=seed)\n",
    "\n",
    "                mid, lo, hi = format_with_errorbars(mid, lo, hi)\n",
    "                mathtext = '{}^{{+{}}}_{{-{}}}'.format(mid, hi, lo)\n",
    "                print('<td>${}$</td>'.format(mathtext), file=f)\n",
    "\n",
    "                results.setdefault('lo', {})[pop] = lo\n",
    "                results.setdefault('mid', {})[pop] = mid\n",
    "                results.setdefault('hi', {})[pop] = hi\n",
    "\n",
    "            print('</tr>', file=f)\n",
    "            print('+-----------+-----------+---------------+---------------+---------------+', file=f_rst)\n",
    "            print('| {:9s} | {:9s} '.format(run, table.meta['network']) + ('| :math:`{:7s}' * 3).format(*results['mid'].values()) + '|', file=f_rst)\n",
    "            print('|           |           ' + ('| ^{:13s}' * 3).format(*('{{+{}}}'.format(_) for _ in results['hi'].values())) + '|', file=f_rst)\n",
    "            print('|           |           ' + ('| _{:13s}' * 3).format(*('{{-{}}}`'.format(_) for _ in results['lo'].values())) + '|', file=f_rst)\n",
    "        print('</tbody>', file=f)\n",
    "        print('</table>', file=f)\n",
    "        print('+-----------+-----------+---------------+---------------+---------------+', file=f_rst)\n",
    "Markdown(f.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = np.random.default_rng(150914)\n",
    "statfunc = np.nanmedian\n",
    "f = io.StringIO()\n",
    "with open('runs/extremes.rst', 'w') as f_rst:\n",
    "    print('+-----------+-----------+---------------+---------------+---------------+', file=f_rst)\n",
    "    print('|           |           | Source class                                  |', file=f_rst)\n",
    "    print('| Observing |           +---------------+---------------+---------------+', file=f_rst)\n",
    "    print('| run       | Network   | BNS           | NSBH          | BBH           |', file=f_rst)\n",
    "    print('+===========+===========+===============+===============+===============+', file=f_rst)\n",
    "    for fieldlabel, statfunc in [\n",
    "                [\n",
    "                    'Percentage of events with area(90) <= 5 deg2',\n",
    "                    lambda _: stats.percentileofscore(_['area(90)'], 5)\n",
    "                ],\n",
    "                [\n",
    "                    'Percentage of events with area(90) <= 20 deg2',\n",
    "                    lambda _: stats.percentileofscore(_['area(90)'], 20)\n",
    "                ],\n",
    "                [\n",
    "                    'Percentage of events with vol(90) <= 1e3 Mpc3',\n",
    "                    lambda _: stats.percentileofscore(_['vol(90)'], 1)\n",
    "                ],\n",
    "                [\n",
    "                    'Percentage of events with vol(90) <= 1e4 Mpc3',\n",
    "                    lambda _: stats.percentileofscore(_['vol(90)'], 10)\n",
    "                ]\n",
    "            ]:\n",
    "        print('| {:69s} |'.format(fieldlabel), file=f_rst)\n",
    "        print('<table>', file=f)\n",
    "        print('<caption>', fieldlabel, '</caption>', file=f)\n",
    "        print('<thead>', file=f)\n",
    "        print('<tr>', file=f)\n",
    "        print('<th>', 'Run', '</th>', file=f)\n",
    "        for pop in pops:\n",
    "            print('<th>', pop, '</th>', file=f)\n",
    "        print('</tr>', file=f)\n",
    "        print('</thead>', file=f)\n",
    "        print('<tbody>', file=f)\n",
    "        for irun, (run, tables1) in enumerate(tables.items()):\n",
    "            print('<tr>', file=f)\n",
    "            print('<th>', run, '</th>', file=f)\n",
    "            for ipop, (pop, table) in enumerate(tables1.items()):\n",
    "                quantiles = [0.05, 0.5, 0.95]\n",
    "                lo, mid, hi = bootstrap.ci(table, statfunc, quantiles, seed=seed)\n",
    "                mid, lo, hi = format_with_errorbars(mid, lo, hi)\n",
    "                mathtext = '{}^{{+{}}}_{{-{}}}'.format(mid, hi, lo)\n",
    "                print('<td>${}$</td>'.format(mathtext), file=f)\n",
    "\n",
    "                results.setdefault('lo', {})[pop] = lo\n",
    "                results.setdefault('mid', {})[pop] = mid\n",
    "                results.setdefault('hi', {})[pop] = hi\n",
    "\n",
    "            print('</tr>', file=f)\n",
    "            print('+-----------+-----------+---------------+---------------+---------------+', file=f_rst)\n",
    "            print('| {:9s} | {:9s} '.format(run, table.meta['network']) + ('| :math:`{:7s}' * 3).format(*results['mid'].values()) + '|', file=f_rst)\n",
    "            print('|           |           ' + ('| ^{:13s}' * 3).format(*('{{+{}}}'.format(_) for _ in results['hi'].values())) + '|', file=f_rst)\n",
    "            print('|           |           ' + ('| _{:13s}' * 3).format(*('{{-{}}}`'.format(_) for _ in results['lo'].values())) + '|', file=f_rst)\n",
    "        print('</tbody>', file=f)\n",
    "        print('</table>', file=f)\n",
    "        print('+-----------+-----------+---------------+---------------+---------------+', file=f_rst)\n",
    "Markdown(f.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('observing-scenarios-simulations-Z5tM87RI-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2339ac3c5b26060c92c2ed40f3a3f5d0e873986aa08541a570f71b18f589e3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
